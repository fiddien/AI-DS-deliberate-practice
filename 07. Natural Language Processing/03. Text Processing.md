### Capturing Text Data
- Plain text
- Tabular data
- Web text (xml/json/html)

### Cleaning
- BeautifulSoup

### Normalization
- make all variations of word into one base word

### Tokenization
- most of times, our "token" is the word, so we split a sentence into words
- NLTK

### Stop Word Removal
- reducing list of words we need to consider

### Part-of-Speech Tagging
- identifying how words are used in a sentence (noun, verb, etc)
- more advanced POS tagging techniques: Hidden Markov Models (HMMs) and Recurrent Neural Networks (RNNs)

### Named Entity Recognition
- identify entities 

### Stemming and Lemmatization
- stemming: reducing a word to its root form
	- sometimes end up with incomplete word
- lemmatization: reducing a word to its dictionary root form


## Typical Workflow
1. Normalize
2. Tokenize
3. Remove Stop Words
4. Stem/Lemmatize