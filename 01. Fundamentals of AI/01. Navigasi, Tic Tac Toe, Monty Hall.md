## Heuristik

*Heuristics* atau heuristik adalah 
> informasi yang bisa berupa aturan, fungsi, atau *constraint* yang membantu algoritma *brute-force* untuk bisa bekerja lebih optimal

Ada dua kata kunci di sini: **algoritma *brute force*** dan **optimal**.

Apa itu *brute force*?

> Melakukan sesuatu secara *brute force* artinya mencoba segala kemungkinan yang terpikirkan, terus menerus, sampai bertemu dengan solusi.

Kita punya algoritma *brute force*. Nah, jika kita ingin membuat algoritma ini enggak "bodoh-bodoh amat", kita bakal ngasih dia suatu aturan *rule of thumb* yang bisa membuat pekerjaan dia jadi terlihat lebih terarah atau punya dasar.

Kedua, *optimal*. Optimal biasanya dikaitkan dengan suatu proses. Keoptimalan suatu proses ini didefinisikan oleh suatu metrik. Masalah keoptimalan dapat terbatas maupun tidak terbatas *constraint*. Kata optimal biasa kita sebandingkan dengan imbuhan ter- (contoh: terpendek, terlama, terbesar).

Ada juga yang namanya *suboptimal*. Suatu hal disebut suboptimal kalau standardnya tidak sebagus yang kita anggap optimal.


## Navigasi

Lihat contoh peta di bawah ini.

![](attachments/Pasted%20image%2020211130073923.png)

Kita akan pergi dari Manchester ke Sheffield. Ada banyak sekali jalan menuju Sheffield. Kita ingin mendapatkan rute perjalanan darat. Berjalan sambil menutup mata pun suatu hari kita akan sampai di destinasi. Tentu, akan ada banyak sekali permutasi ruas jalan yang bisa dilalui, dengan berbagai jarak tempuh. Namun, jika kita menginginkan rute paling **optimal**, dalam hal ini jarak terpendek, bagaimana cara mencari rute tersebut?

Coba kita pikirkan sendiri, bagaimana cara kita akan mencari rute terpendek secara manual?

Pertama, dapat dilihat bahwa Sheffield itu berada di tenggaranya Manchester. Aturan pertama yang bisa kita terapkan adalah **utamakan jalan berarah timur atau selatan**, karena jalan ke arah barat atau utara akan semakin menjauhi kota tujuan, kan?

Kemudian, fokuslah pada ruas jalan terdekat. Catat jalan berarah timur atau selatan dari posisi awal kita. Lalu fokus ke ruas jalan selanjutnya yang menuju timur atau selatan lagi. Pindah ke ruas jalan ketiga, dan seterusnya.

Harapannya, kita sekarang punya beberapa kemungkinan rute suboptimal yang lebih sedikit. Tinggal kita hitung jarak tempuh tiap rute. Akhirnya, kita menemukan rute terpendek.

Tadi adalah salah satu algorima heuristik.

![](attachments/Pasted%20image%2020211130075827.png)

Nah, tapi ini bermasalah. Kita hanya memerhatikan arah ruas jalan terdekat saja. Bisa saja ada ruas jalan berarah barat atau utara dari suatu titik tertentu yang akhirnya mengantarkan kita ke rute yang lebih pendek. Untuk sekarang, kita tidak pernah tahu jika tidak melihat semua kemungkinan. Kita hanya menggunakan heuristik arah per ruas jalan.

Ada pula heuristik lain yaitu, berdasarkan jarak (*direct distance*). Algoritma ini dinamai **A\* Search**, salah satu algoritma AI yang efektif. Akan kita pelajari segera.

![](attachments/Pasted%20image%2020211130081800.png)

## Permainan Tic Tac Toe

### Representasi masalah

Sudah familiar dengan permainan Tic Tac Toe, kan?

![](attachments/Pasted%20image%2020211130082833.png)

Bagaimana cara merepresentasikan permainan Tic Tac Toe ke komputer?

Kita kemungkinan akan menggunakan tipe data graf (*graph*) karena graf lebih fleksibel dalam memodelkan hubungan antar item.

Ada beberapa pilihan representasi.

Representasi A: Secara sederhana memodelkan kotak sebagai titik (*node*) di graf lalu menghubungkan setiap titik, sehingga graf Tic Tac Toe A kita adalah graf lengkap.

![](attachments/Pasted%20image%2020211130082910.png)

Representasi B: Mirip dengan A, hanya saja dua titiknya kita tulis sebagai posisi baris dan kolom yang pilihannya angkanya {0, 1, 2}. Contoh: titik (0, 0) dan titik (2, 1). Dua titik bertetangga jika selisih baris dan kolom antara keduanya paling banyak 1. Contoh: (0, 1) bertetangga dengan (1, 0) tapi tidak dengan (2, 2).

Representasi C: Mirip dengan B, tapi kita mencatat posisi lawan juga. Titik direpresentasikan sebagai tuple <posisi kita, posisi lawan>. Mereka terhubung dengan aturan yang sama seperti Representasi B.

Representasi D: Anggap setiap kemungkinan papan Tic Tac Toe sebagai titik itu sendiri. Dua titik terhubung jika ada *langkah valid* yang bisa pemain lakukan dari papan tersebut. Perhatikan bahwa artinya graf ini adalah graf berarah. Setelah menulis X atau O di papan, kita tidak bisa menghapusnya, kan?

![](attachments/Pasted%20image%2020211130082933.png)

### Pruning to search tree

Jika kita menggunakan representasi D, akan ada banyak sekali kemungkinan "rute" permainan. Ada 9! (9 faktorial) kemungkinan!

![](attachments/Pasted%20image%2020211130084528.png)

Tapi ada beberapa *langkah* yang tidak berguna atau bodoh, seperti ini contohnya:

![](attachments/Pasted%20image%2020211130084654.png)

Kita bisa mengeleminasi *langkah* tersebut. Proses mengevaluasi kondisi masalah ini disebut sebagai ***pruning the search tree*** âœ‚ğŸŒ³.

Perlu diingat juga, dalam suatu permainan, kita akan menghadapi lawan yang ingin menang seperti halnya algoritma kita. Jika kita melakukan langkah yang tidak strategis berkali-kali, lawan akan berusaha merebut kemenangan seefisien mungkin.

![](attachments/Pasted%20image%2020211130085103.png)

Inilah gambaran singkat dari **Adversarial Search**. Kita akan coba ekplorasi masalah ini salah satunya dengan menggunakan **Algoritma Mini-Max** (lawan permainan ingin meminimalkan kemenangan kita sedangkan kita ingin memaksimalkannya).

## Monty Hall Problem

### Prior Probability
Masih ingat Monty Hall Problem, kan?

Monty Hall punya tiga pintu yang menuju masing-masing suatu ruangan: A, B, dan C. Salah satunya terdapat mobil sedangkan yang lain hanya kambing, kita tidak tahu yang mana berisi apa. Kita akan membawa pulang isi dari pintu yang kita pilih di akhir permainan.

Kita akan diminta untuk memilih satu di antara ketiga pintu, lalu Monty akan membuka satu persatu pintu yang tidak kita pilih. Di setiap setelah suatu pintu dibuka, kita diberikan kesempatan untuk mempertahankan pilihan kita atau menggantinya dengan pintu lain. Pintu kitalah yang akan dibuka terakhir. 

Kita sebagai orang yang pernah belajar peluang, pasti akan memikirkan ini.
- P(mobil di A) + P(mobil di B) + P(mobil di C) = 1
- P(mobil di A) = P(mobil di B) = P(mobil di C) = 1/3

Peluang-peluang di atas dinamakan *peluang priori* atau *prior probability*: peluang yang dihitung tanpa mengetahui pengetahuan di lapangan.

Permainan dimulai. Misalkan kita memilih pintu A, maka Monty membuka pintu yang lain, B. Ternyata isinya adalah kambing. Jelas, mobil tidak ada di B.

Selanjutnya, apa langkah yang akan kita pilih? Tetap di pintu A, atau berpindah ke pintu C? Apa strategi umum jika kita ingin memenangkan permainan ini (mendapatkan mobil)? *Stay* or *switch*?

### Posterior Probability

Mari kita perbarui catatan kita tentang peluang tadi. Berapa peluang setelah B dibuka ternyata ada mobil di B? 0.
- P(mobil di B|B dibuka) = 0

Tapi berapa P(mobil di A) dan P(hadiah di C) sekarang? 1/2?

Salah. Dan pertanyaannya kurang tepat. Tentu secara implisit aturannya adalah Monty akan selalu membuka pintu yang di dalamnya tidak ada mobil (simpan kejutannya di akhir-akhir). Karena sekarang kita sudah punya pengetahuan tentang isi pintu B, maka peluang yang dicari adalah P(mobil di A|B dibuka) dan P(hadiah di C|B dibuka). Inilah yang disebut *posterior probability*: peluang yang dihitung setelah kita memiliki informasi tambahan di lapangan.

### Teorema Bayes

Mari kita perhatikan pilihan untuk berganti ke pintu C. Kita memilih strategy *switch*. 

Berapa peluang mobil ada di C ketika pintu B sudah dibuka? Untuk menghitung peluang posterior ini, kita membutuhkan bantuan Teorema Bayes.

- P(mobil di C|B dibuka) = P(B dibuka|mobil di C) * P(mobil di C) / P(B dibuka)

Mari kita cari nilai dari tiap peluang di persamaan di atas.

Ingat bahwa kita memilih pintu A di awal tadi dan Monty membuka pintu B. Jika Monty memilih B maka ada dua kemungkinan:
- Mobil di C. Ia terpaksa harus membuka B (pintu A tidak mungkin dibuka karena itu pilihan kita saat itu). Artinya,
	- P(B dibuka|mobil di C) = 1,
	- P(B dibuka|mobil di A) = 0.
- Mobil di A. Monty bebas saja mau membuka pintu B atau C. Artinya,
	- P(B dibuka|mobil di A) = P(C dibuka|mobil di A) = 1/2

Lalu, P(mobil di C) = 1/3, sesuai dengan peluang prior yang kita catat.

Nah, mencari P(B dibuka) ini cukup rumit. Kita gunakan **marginal probability**.

P(B dibuka) 

= P(mobil di A) * P(B dibuka|mobil di A) 

   \+ P(mobil di B) * P(B dibuka|mobil di B)

   \+ P(mobil di C) * P(B dibuka|mobil di C)

= 1/3 \* 1/2 + 1/3 \* 0 + 1/3 \* 1

= 1/6 + 1/3

= 1/2

Kita masukkan peluang-peluang di atas:

P(mobil di C|B dibuka) 

= P(B dibuka|mobil di C) * P(mobil di C) / P(B dibuka) 

= 1 * 1/3 / 1/2 

= 2/3

Wow, peluang kemenangan kita naik!

Namun bagaimana jika kita tetap memilih pintu A atau *stay*?

P(mobil di A|B dibuka) 

= P(B dibuka|mobil di A) * P(mobil di A) / P(B dibuka)

= 1/2 * 1/3 / 1/2

= 1/3

Wah, peluang kemenangan kita jauh lebih kecil dari pada strategi *switch*!

Ternyata, berdasarkan pandangan peluang, strategi *switch* selalu lebih baik dalam menghadapi Monty Hall Problem. 

Tidak intuitif, ya? Tapi menarik, bukan?

## Apa itu kecerdasan?

Definisi yang bermasalah

> Algoritma dan fungsi: mereka cerdas kalau kita tidak bisa menjelaskan kecerdasannya.

Untuk tujuan produktif kita, kita harus mendefinisikan *kecerdasan* *sesuatu* bukan berasal dari bagaimana kita mempersepsikan *sesuatu*, tapi harus datang dari sistem *sesuatu*nya itu sendiri.

> Sesuatu memiliki kecerdasan dalam mengerjakan tugas X, baik secara biologis maupun artifisial, berasal dari keberhasilannya mengerjakan suatu tugas X.

Sesuatu memiliki kecerdasan secara umum: ia bisa mengerjakan berbagai macam tugas. Referensi utama kita dalam hal ini adalah manusia.

## Agent, Environment, State

![](attachments/Pasted%20image%2020211130111916.png)

Beberapa istilah penting:
- *Environment*: dunia, tempat menerima aksi dan memberikan timbal balik kepada apapun yang ada di dalamnya.
- *Agent*: sesuatu yang dapat memberikan *actions* pada *environment*, umumnya memiliki sensor untuk mencerna *perception* dari *environment*, motor atau *affectors* untuk bergerak, dan keputusan atau *cognition* untuk memilih *action* selanjutnya.
	- Misalkan kasusnya adalah robot. Apakah agent ini adalah robot secara keseluruhan atau software yang terinstal di dalamnya?
- *State*: informasi penting mengenai kejadian/posisi dari *agent* pada suatu *environment*.
	- *Goal state*: *state* akhir yang dituju oleh *agent*.

Kita dapat membagi *agents* ke dalam beberapa jenis, seperti:
- Knowledge-based agent
- Planning agent
- Learning agent


## Tipe Masalah Kecerdasan Artifisial

**Environment States**
- Seberapa banyak variabel yang diketahui dalam satu waktu
	- Fully Observable, seperti di permainan Tic Tac Toe
	- Partially Observable, seperti di permainan RPG
- Sifat hasil dari actions
	- Deterministic, setiap actions jelas diketahui hasilnya
	- Stochastic, hasil dari setiap actions memiliki unsur ketidakpastian (peluang)
- Sifat states
	- Discrete, dapat dihitung atau dicacah
	- Continous, tak terhitung, biasanya dipetakan ke bilangan ril
- Sifat environment/banyaknya agents
	- Benign, hanya ada satu agent yang dapat melakukan actions
	- Adversarial, ada banyak agent yang melakukan actions, biasanya ada unsur kompetitif


Contoh:
- Bermain poker: partially observable, stochastic, discrete, adversarial
- Memahami tulisan tangan: fully observable, stochastic, contionus, benign
- Menjalankan mobil di jalan: partially observable, stochastic, contionous, benign
- Bermain catur: fully observable, deterministic, discrete, adversarial

---

Jadi, apa itu kecerdasan?
> Suatu agen yang cerdas adalah agen yang mengambil aksi untuk memaksimalkan fungsi utamanya untuk suatu tujuan.

dalam kata lain, mereka yang melakukan *aksi yang rasional*.

Tapi, biasanya selalu ada *constraint* dalam menghadapi masalah, seperti partially observable environment, atau sumber daya komputasional yang terbatas. Kita tidak selalu bisa mengharapkan aksi yang optimal dari suatu agent. Inilah munculnya konsep *bounded optimality*, keoptimalan dengan batasan-batasan yang ditentukan. 